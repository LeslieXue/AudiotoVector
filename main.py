from util import batch_convert_json_to_csv
from audio_segment_DataGen import get_segment_vectors, get_segment_vectors_single
import os, glob, json, random
import pandas as pd
import numpy as np
from audio_segment_TrainTest import load_samples_from_paths, split_data, train, test


if __name__ == "__main__":
    '''
    input_folder = "random_samples"
    f0mode = "normal"  # å¯é€‰: "normal", "fft", "crepe", "pyin"
    segment_duration_ms = 20
    shiftmode = "ratio"  # å¯é€‰: "key", "ratio"
    shift_point = (1/3, 1/2, 1)
    label_adj = (1/5, 1/4, 1/3, 1/2, 2/3, 1, 3/2, 2, 3, 4, 5)

    # æ„å»ºè¾“å‡ºç‰¹å¾æ–‡ä»¶å¤¹åï¼Œéµå¾ª get_segment_vectors å‚æ•°è§„åˆ™
    feature_folder = f"features_{f0mode}_{shiftmode}_{len(shift_point)}shift_{len(label_adj)}point"
    os.makedirs(feature_folder, exist_ok=True)

    print("ğŸš€ å¼€å§‹éå† CSV å¹¶æå–ç‰¹å¾...")
    for filename in os.listdir(input_folder):
        if not filename.endswith(".csv"):
            continue
        csv_path = os.path.join(input_folder, filename)
        print(f"å¤„ç†æ–‡ä»¶: {csv_path}")
        # è°ƒç”¨ get_segment_vectors ç”Ÿæˆç‰¹å¾æ–‡ä»¶
        # è¿™é‡Œä½¿ç”¨ get_segment_vectors_single å¹¶åœ¨å…¶åŸºç¡€ä¸Šå¤„ç†å‘é‡å­—æ®µæ ¼å¼åŒ–
        segment_features = get_segment_vectors_single(
            csv_path=csv_path,
            audio_path=csv_path.replace('.csv', '.wav'),
            output_csv_path=os.path.join(feature_folder,f"{filename}_features.csv"),
            f0mode=f0mode,
            segment_duration_ms=segment_duration_ms,
            shiftmode=shiftmode,
            shift_point=shift_point,
            label_adj=label_adj
        )
        
    print(f"âœ… æ‰€æœ‰ç‰¹å¾æ–‡ä»¶å·²ç”Ÿæˆï¼Œå­˜æ”¾åœ¨ {feature_folder}")
    '''
    data_folder = "features_normal_ratio_3shift_11point"
    allowed_labels = [2, 4, 5]
    point = 11
    model_path = "f11_model.pt"
    all_csv_paths = glob.glob(os.path.join(data_folder, "*.csv"))
    random.seed(42)
    random.shuffle(all_csv_paths)
    half = len(all_csv_paths) // 2
    selected_train_files = all_csv_paths[:half]
    selected_test_files = all_csv_paths[half:]
    
    print(f"ğŸ” é€‰ä¸­è®­ç»ƒæ–‡ä»¶æ•°: {len(selected_train_files)}")
    print(f"ğŸ” é€‰ä¸­æµ‹è¯•æ–‡ä»¶æ•°: {len(selected_test_files)}")

    print("ğŸš€ åŠ è½½è®­ç»ƒæ ·æœ¬...")
    train_samples = load_samples_from_paths(selected_train_files, allowed_labels=allowed_labels, point=point)
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_samples)}")

    # æŒ‰æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
    train_samples, val_samples, _ = split_data(train_samples, train_ratio=0.7, val_ratio=0.1)

    print("ğŸš€ åŠ è½½æµ‹è¯•æ ·æœ¬...")
    test_samples = load_samples_from_paths(selected_test_files, allowed_labels=allowed_labels, point=point)
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}")
    
    train_labels = [y for _, y in train_samples]
    print(f"è®­ç»ƒé›†ä¸­å®é™…ä½¿ç”¨çš„æ ‡ç­¾ç§ç±»: {sorted(set(train_labels))}")

    train(train_samples=train_samples, val_samples=val_samples, max_samples= 50000, model_path=model_path, nc=11)
    test(test_samples=test_samples, model_path=model_path, nc=11)
